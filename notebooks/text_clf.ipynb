{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1031c6d-daeb-4c0b-91ee-5e850befb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2089058f-3ff4-4087-9786-73a3d3f18708",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting boto3>=1.20.27 (from flair)\n",
      "  Downloading boto3-1.34.43-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting bpemb>=0.3.2 (from flair)\n",
      "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
      "Collecting conllu>=4.0 (from flair)\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecated>=1.2.13 (from flair)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ftfy>=6.1.0 (from flair)\n",
      "  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting gdown>=4.4.0 (from flair)\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting gensim>=4.2.0 (from flair)\n",
      "  Downloading gensim-4.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from flair) (0.20.3)\n",
      "Collecting janome>=0.4.2 (from flair)\n",
      "  Downloading Janome-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from flair) (1.0.9)\n",
      "Collecting lxml>=4.8.0 (from flair)\n",
      "  Using cached lxml-5.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from flair) (3.7.4)\n",
      "Requirement already satisfied: more-itertools>=8.13.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from flair) (10.2.0)\n",
      "Collecting mpld3>=0.3 (from flair)\n",
      "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pptree>=3.1 (from flair)\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from flair) (2.8.2)\n",
      "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Collecting regex>=2022.1.18 (from flair)\n",
      "  Using cached regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting scikit-learn>=1.0.2 (from flair)\n",
      "  Using cached scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting segtok>=1.5.11 (from flair)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tabulate>=0.8.10 (from flair)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from flair) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.63.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from flair) (4.66.1)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
      "  Downloading transformer_smaller_training_vocab-0.3.3-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting transformers<5.0.0,>=4.18.0 (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<2.0.0,>=1.0.0 (from flair)\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair)\n",
      "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting semver<4.0.0,>=3.0.0 (from flair)\n",
      "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.43 (from boto3>=1.20.27->flair)\n",
      "  Downloading botocore-1.34.43-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.20.27->flair)\n",
      "  Using cached s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from bpemb>=0.3.2->flair) (1.24.4)\n",
      "Requirement already satisfied: requests in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from bpemb>=0.3.2->flair) (2.31.0)\n",
      "Collecting sentencepiece (from bpemb>=0.3.2->flair)\n",
      "  Downloading sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.13->flair)\n",
      "  Downloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from gdown>=4.4.0->flair) (4.12.3)\n",
      "Requirement already satisfied: filelock in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from gdown>=4.4.0->flair) (3.13.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from gensim>=4.2.0->flair) (1.10.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim>=4.2.0->flair)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (2024.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (23.2)\n",
      "Requirement already satisfied: six in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from langdetect>=1.0.9->flair) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (6.1.1)\n",
      "Requirement already satisfied: jinja2 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from mpld3>=0.3->flair) (3.1.3)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=1.0.2->flair)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=1.0.2->flair)\n",
      "  Downloading threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sympy in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.8,>=1.5.0->flair) (12.3.101)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
      "  Downloading tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
      "  Downloading safetensors-0.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: protobuf in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (4.25.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib>=2.2.3->flair) (3.17.0)\n",
      "Collecting accelerate>=0.21.0 (from transformers[torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair)\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from jinja2->mpld3>=0.3->flair) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from requests->bpemb>=0.3.2->flair) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from requests->bpemb>=0.3.2->flair) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from requests->bpemb>=0.3.2->flair) (2024.2.2)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=4.4.0->flair)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
      "Requirement already satisfied: psutil in /home/ajkdrag/workspace/chequeparser/venv/lib/python3.8/site-packages (from accelerate>=0.21.0->transformers[torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.8)\n",
      "Downloading flair-0.13.1-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.34.43-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading gensim-4.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached lxml-5.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
      "Downloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n",
      "Using cached scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Downloading transformer_smaller_training_vocab-0.3.3-py3-none-any.whl (14 kB)\n",
      "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
      "Downloading botocore-1.34.43-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "Downloading safetensors-0.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Downloading tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pptree, sqlitedict\n",
      "  Building wheel for pptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4628 sha256=6ea2a34c42d065b552116a57324d7b2deff67319e11c2283bcafaf7736d71d3c\n",
      "  Stored in directory: /home/ajkdrag/.cache/pip/wheels/e1/8b/30/5b20240d3d13a9dfafb6a6dd49d1b541c86d39812cb3690edf\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16853 sha256=d71a8f21e485716b02ba8a82ffd3b082484bc95c7696f19058a21cf5e99dd6b4\n",
      "  Stored in directory: /home/ajkdrag/.cache/pip/wheels/04/c6/16/46e174009277f9bccdaa7215a243939d2f70180804b249bf3a\n",
      "Successfully built pptree sqlitedict\n",
      "Installing collected packages: sqlitedict, sentencepiece, pptree, janome, wrapt, urllib3, threadpoolctl, tabulate, smart-open, semver, safetensors, regex, PySocks, lxml, joblib, jmespath, ftfy, conllu, segtok, scikit-learn, gensim, deprecated, botocore, wikipedia-api, s3transfer, mpld3, bpemb, tokenizers, pytorch-revgrad, gdown, boto3, accelerate, transformers, transformer-smaller-training-vocab, flair\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.0\n",
      "    Uninstalling urllib3-2.2.0:\n",
      "      Successfully uninstalled urllib3-2.2.0\n",
      "Successfully installed PySocks-1.7.1 accelerate-0.27.2 boto3-1.34.43 botocore-1.34.43 bpemb-0.3.4 conllu-4.5.3 deprecated-1.2.14 flair-0.13.1 ftfy-6.1.3 gdown-5.1.0 gensim-4.3.2 janome-0.5.0 jmespath-1.0.1 joblib-1.3.2 lxml-5.1.0 mpld3-0.5.10 pptree-3.1 pytorch-revgrad-0.2.0 regex-2023.12.25 s3transfer-0.10.0 safetensors-0.4.2 scikit-learn-1.3.2 segtok-1.5.11 semver-3.0.2 sentencepiece-0.1.99 smart-open-6.4.0 sqlitedict-2.1.0 tabulate-0.9.0 threadpoolctl-3.3.0 tokenizers-0.15.2 transformer-smaller-training-vocab-0.3.3 transformers-4.37.2 urllib3-1.26.18 wikipedia-api-0.6.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e01ad001-eba2-4e51-89be-5fc500f3fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import TREC_6\n",
    "from flair.models import TARSClassifier\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be634c58-5472-40f1-bf98-388f4639ec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:47:23,715 TARS initialized without a task. You need to call .add_and_switch_to_new_task() before training this model\n"
     ]
    }
   ],
   "source": [
    "tars = TARSClassifier.load(\"tars-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adf120fd-95a6-4573-a756-f84d2dab2928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:52:29,947 No dev split found. Using 0% (i.e. 0 samples) of the train split as dev data\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import FlairDatapointDataset\n",
    "# training dataset consisting of four sentences (2 labeled as \"olahraga\" (sports) and 2 labeled as \"politik\" (politics)\n",
    "train = FlairDatapointDataset(\n",
    "    [\n",
    "        Sentence('BSN Sports LLC')\n",
    "        .add_label('payee_or_misc', 'payee'),\n",
    "        Sentence('Samuel L. Catherin')\n",
    "        .add_label('payee_or_misc', 'payee'),\n",
    "        Sentence('Five Seasons')\n",
    "        .add_label('payee_or_misc', 'payee'),\n",
    "        Sentence('fifty thousand and 00/11')\n",
    "        .add_label('payee_or_misc', 'misc'),\n",
    "        Sentence('Official check')\n",
    "        .add_label('payee_or_misc', 'misc')\n",
    "    ])\n",
    "test = FlairDatapointDataset(\n",
    "    [\n",
    "        Sentence('Central hudson electric').add_label('payee_or_misc', 'payee'),\n",
    "        Sentence('Pay to the order of').add_label('payee_or_misc', 'misc')\n",
    "    ])\n",
    "# make a corpus with train and test split\n",
    "corpus = Corpus(train=train, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7cdfb01-0038-4d2a-8bf1-15a0a9724058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:54:53,433 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "5it [00:00, 12710.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:54:53,439 Dictionary created for label 'payee_or_misc' with 2 values: payee (seen 3 times), misc (seen 2 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<flair.data.Dictionary at 0x7f01fec99be0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.make_label_dictionary(label_type=\"payee_or_misc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf76001c-4371-424b-93d4-281be8e69dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:55:25,508 TARS initialized without a task. You need to call .add_and_switch_to_new_task() before training this model\n",
      "2024-02-17 00:55:25,567 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "5it [00:00, 12045.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:55:25,573 Dictionary created for label 'payee_or_misc' with 2 values: payee (seen 3 times), misc (seen 2 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "# 1. load base TARS\n",
    "tars = TARSClassifier.load('tars-base')\n",
    "# 2. make the model aware of the desired set of labels from the new corpus\n",
    "tars.add_and_switch_to_new_task(\"PAYEE_OR_MISC\", \n",
    "                                label_dictionary=corpus.make_label_dictionary(\"payee_or_misc\"),\n",
    "                                label_type=\"payee_or_misc\")\n",
    "# 3. initialize the text classifier trainer with your corpus\n",
    "trainer = ModelTrainer(tars, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c53f33b0-9592-47bb-8823-7715405bc505",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:55:51,709 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,711 Model: \"TARSClassifier(\n",
      "  (tars_model): TextClassifier(\n",
      "    (embeddings): TransformerDocumentEmbeddings(\n",
      "      (model): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0-11): 12 x BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (locked_dropout): LockedDropout(p=0.0)\n",
      "    (word_dropout): WordDropout(p=0.0)\n",
      "    (loss_function): CrossEntropyLoss()\n",
      "  )\n",
      ")\"\n",
      "2024-02-17 00:55:51,712 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,712 Corpus: 5 train + 0 dev + 2 test sentences\n",
      "2024-02-17 00:55:51,713 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,713 Train:  5 sentences\n",
      "2024-02-17 00:55:51,714         (train_with_dev=False, train_with_test=False)\n",
      "2024-02-17 00:55:51,714 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,715 Training Params:\n",
      "2024-02-17 00:55:51,715  - learning_rate: \"0.02\" \n",
      "2024-02-17 00:55:51,715  - mini_batch_size: \"1\"\n",
      "2024-02-17 00:55:51,716  - max_epochs: \"10\"\n",
      "2024-02-17 00:55:51,716  - shuffle: \"True\"\n",
      "2024-02-17 00:55:51,717 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,717 Plugins:\n",
      "2024-02-17 00:55:51,718  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
      "2024-02-17 00:55:51,718 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,719 Final evaluation on model from best epoch (best-model.pt)\n",
      "2024-02-17 00:55:51,719  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-02-17 00:55:51,722 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,722 Computation:\n",
      "2024-02-17 00:55:51,723  - compute on device: cuda:0\n",
      "2024-02-17 00:55:51,724  - embedding storage: cpu\n",
      "2024-02-17 00:55:51,724 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,725 Model training base path: \"resources/taggers/payee\"\n",
      "2024-02-17 00:55:51,725 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,726 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,803 epoch 1 - iter 1/5 - loss 2.10815310 - time (sec): 0.05 - samples/sec: 40.92 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:51,834 epoch 1 - iter 2/5 - loss 1.52426022 - time (sec): 0.08 - samples/sec: 50.02 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:51,871 epoch 1 - iter 3/5 - loss 1.86336601 - time (sec): 0.12 - samples/sec: 51.29 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:51,910 epoch 1 - iter 4/5 - loss 1.93622264 - time (sec): 0.16 - samples/sec: 51.14 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:51,939 epoch 1 - iter 5/5 - loss 1.97919791 - time (sec): 0.19 - samples/sec: 53.96 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:51,940 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,941 EPOCH 1 done: loss 1.9792 - lr: 0.020000\n",
      "2024-02-17 00:55:51,942  - 0 epochs without improvement\n",
      "2024-02-17 00:55:51,943 saving best model\n",
      "2024-02-17 00:55:52,373 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,412 epoch 2 - iter 1/5 - loss 0.68676007 - time (sec): 0.03 - samples/sec: 77.06 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,442 epoch 2 - iter 2/5 - loss 0.84860581 - time (sec): 0.06 - samples/sec: 71.94 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,471 epoch 2 - iter 3/5 - loss 0.84427923 - time (sec): 0.08 - samples/sec: 70.72 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,500 epoch 2 - iter 4/5 - loss 0.80891456 - time (sec): 0.11 - samples/sec: 70.44 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,533 epoch 2 - iter 5/5 - loss 0.76621665 - time (sec): 0.15 - samples/sec: 67.86 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,534 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,535 EPOCH 2 done: loss 0.7662 - lr: 0.020000\n",
      "2024-02-17 00:55:52,536  - 1 epochs without improvement\n",
      "2024-02-17 00:55:52,538 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,581 epoch 3 - iter 1/5 - loss 0.13155100 - time (sec): 0.03 - samples/sec: 64.92 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,610 epoch 3 - iter 2/5 - loss 0.51108031 - time (sec): 0.06 - samples/sec: 66.26 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,645 epoch 3 - iter 3/5 - loss 0.91648836 - time (sec): 0.10 - samples/sec: 62.89 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,675 epoch 3 - iter 4/5 - loss 0.73741844 - time (sec): 0.12 - samples/sec: 64.13 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,704 epoch 3 - iter 5/5 - loss 0.61619696 - time (sec): 0.15 - samples/sec: 64.82 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,705 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,706 EPOCH 3 done: loss 0.6162 - lr: 0.020000\n",
      "2024-02-17 00:55:52,707  - 2 epochs without improvement\n",
      "2024-02-17 00:55:52,708 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,746 epoch 4 - iter 1/5 - loss 0.04814388 - time (sec): 0.03 - samples/sec: 76.11 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,781 epoch 4 - iter 2/5 - loss 0.03209685 - time (sec): 0.06 - samples/sec: 65.03 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,817 epoch 4 - iter 3/5 - loss 0.02594506 - time (sec): 0.10 - samples/sec: 61.85 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,846 epoch 4 - iter 4/5 - loss 0.20615928 - time (sec): 0.13 - samples/sec: 63.26 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,876 epoch 4 - iter 5/5 - loss 0.16739294 - time (sec): 0.16 - samples/sec: 63.95 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,877 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,878 EPOCH 4 done: loss 0.1674 - lr: 0.020000\n",
      "2024-02-17 00:55:52,879  - 3 epochs without improvement\n",
      "2024-02-17 00:55:52,880 saving best model\n",
      "2024-02-17 00:55:53,435 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:53,477 epoch 5 - iter 1/5 - loss 0.00357518 - time (sec): 0.03 - samples/sec: 76.27 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,505 epoch 5 - iter 2/5 - loss 0.05364135 - time (sec): 0.05 - samples/sec: 73.05 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,535 epoch 5 - iter 3/5 - loss 0.04225065 - time (sec): 0.08 - samples/sec: 70.62 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,575 epoch 5 - iter 4/5 - loss 0.03348753 - time (sec): 0.13 - samples/sec: 63.95 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,604 epoch 5 - iter 5/5 - loss 0.05917075 - time (sec): 0.15 - samples/sec: 65.02 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,605 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:53,605 EPOCH 5 done: loss 0.0592 - lr: 0.020000\n",
      "2024-02-17 00:55:53,607  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.01]\n",
      "2024-02-17 00:55:53,608 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:53,647 epoch 6 - iter 1/5 - loss 0.00647313 - time (sec): 0.03 - samples/sec: 76.94 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,676 epoch 6 - iter 2/5 - loss 0.01799789 - time (sec): 0.05 - samples/sec: 72.81 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,710 epoch 6 - iter 3/5 - loss 0.01216121 - time (sec): 0.09 - samples/sec: 67.53 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,742 epoch 6 - iter 4/5 - loss 0.00992067 - time (sec): 0.12 - samples/sec: 65.88 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,780 epoch 6 - iter 5/5 - loss 0.00907170 - time (sec): 0.16 - samples/sec: 62.79 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,781 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:53,782 EPOCH 6 done: loss 0.0091 - lr: 0.010000\n",
      "2024-02-17 00:55:53,783  - 1 epochs without improvement\n",
      "2024-02-17 00:55:53,784 saving best model\n",
      "2024-02-17 00:55:54,185 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,241 epoch 7 - iter 1/5 - loss 0.00313355 - time (sec): 0.03 - samples/sec: 72.51 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,270 epoch 7 - iter 2/5 - loss 0.00177167 - time (sec): 0.06 - samples/sec: 70.10 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,301 epoch 7 - iter 3/5 - loss 0.00205998 - time (sec): 0.09 - samples/sec: 67.87 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,338 epoch 7 - iter 4/5 - loss 0.00171531 - time (sec): 0.13 - samples/sec: 63.93 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,370 epoch 7 - iter 5/5 - loss 0.00175350 - time (sec): 0.16 - samples/sec: 63.75 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,371 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,371 EPOCH 7 done: loss 0.0018 - lr: 0.010000\n",
      "2024-02-17 00:55:54,373  - 2 epochs without improvement\n",
      "2024-02-17 00:55:54,374 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,413 epoch 8 - iter 1/5 - loss 0.00157913 - time (sec): 0.03 - samples/sec: 75.08 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,443 epoch 8 - iter 2/5 - loss 0.00095258 - time (sec): 0.06 - samples/sec: 71.17 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,472 epoch 8 - iter 3/5 - loss 0.00663488 - time (sec): 0.09 - samples/sec: 69.91 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,510 epoch 8 - iter 4/5 - loss 0.00516349 - time (sec): 0.12 - samples/sec: 64.92 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,538 epoch 8 - iter 5/5 - loss 0.00415431 - time (sec): 0.15 - samples/sec: 65.72 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,539 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,540 EPOCH 8 done: loss 0.0042 - lr: 0.010000\n",
      "2024-02-17 00:55:54,541  - 3 epochs without improvement\n",
      "2024-02-17 00:55:54,543 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,591 epoch 9 - iter 1/5 - loss 0.00200971 - time (sec): 0.03 - samples/sec: 74.88 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,619 epoch 9 - iter 2/5 - loss 0.00166987 - time (sec): 0.05 - samples/sec: 73.35 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,648 epoch 9 - iter 3/5 - loss 0.00121260 - time (sec): 0.08 - samples/sec: 71.76 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,678 epoch 9 - iter 4/5 - loss 0.00142340 - time (sec): 0.11 - samples/sec: 70.38 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,713 epoch 9 - iter 5/5 - loss 0.00147699 - time (sec): 0.15 - samples/sec: 67.13 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,714 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,715 EPOCH 9 done: loss 0.0015 - lr: 0.010000\n",
      "2024-02-17 00:55:54,716  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.005]\n",
      "2024-02-17 00:55:54,717 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,756 epoch 10 - iter 1/5 - loss 0.00121854 - time (sec): 0.03 - samples/sec: 73.37 - lr: 0.005000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,803 epoch 10 - iter 2/5 - loss 0.00298219 - time (sec): 0.07 - samples/sec: 54.20 - lr: 0.005000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,830 epoch 10 - iter 3/5 - loss 0.00254319 - time (sec): 0.10 - samples/sec: 59.22 - lr: 0.005000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,866 epoch 10 - iter 4/5 - loss 0.00224540 - time (sec): 0.14 - samples/sec: 58.51 - lr: 0.005000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,902 epoch 10 - iter 5/5 - loss 0.00187507 - time (sec): 0.17 - samples/sec: 57.90 - lr: 0.005000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,903 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,903 EPOCH 10 done: loss 0.0019 - lr: 0.005000\n",
      "2024-02-17 00:55:54,904  - 1 epochs without improvement\n",
      "2024-02-17 00:55:55,542 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:55,544 Loading model from best epoch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 89.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:55:57,553 \n",
      "Results:\n",
      "- F-score (micro) 0.5\n",
      "- F-score (macro) 0.3333\n",
      "- Accuracy 0.5\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       payee     0.5000    1.0000    0.6667         1\n",
      "        misc     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.5000         2\n",
      "   macro avg     0.2500    0.5000    0.3333         2\n",
      "weighted avg     0.2500    0.5000    0.3333         2\n",
      "\n",
      "2024-02-17 00:55:57,554 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.5}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. train model\n",
    "trainer.train(base_path='resources/taggers/payee', # path to store the model artifacts\n",
    "              learning_rate=0.02, \n",
    "              mini_batch_size=1, \n",
    "              max_epochs=10, \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cfce056-c57d-4986-959c-9c6b6b8fadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load few-shot TARS model\n",
    "tars = TARSClassifier.load('resources/taggers/payee/final-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45cd4fe1-f558-42e6-b704-29285ec0e531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[3]: \"Weber County Treasurer\"\n"
     ]
    }
   ],
   "source": [
    "# 6. Prepare a test sentence\n",
    "sentence = Sentence(\"Weber County Treasurer\")\n",
    "# 7. Predict for olahraga and politik\n",
    "tars.predict(sentence, return_probabilities_for_all_classes=True)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e42c4f-46f2-463f-ae6f-b98f04525040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
