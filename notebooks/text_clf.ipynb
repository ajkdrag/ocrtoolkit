{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1031c6d-daeb-4c0b-91ee-5e850befb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2089058f-3ff4-4087-9786-73a3d3f18708",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting boto3>=1.20.27 (from flair)\n",
      "  Downloading boto3-1.34.43-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting bpemb>=0.3.2 (from flair)\n",
      "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
      "Collecting conllu>=4.0 (from flair)\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecated>=1.2.13 (from flair)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ftfy>=6.1.0 (from flair)\n",
      "  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting gdown>=4.4.0 (from flair)\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting gensim>=4.2.0 (from flair)\n",
      "  Downloading gensim-4.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from flair) (0.20.3)\n",
      "Collecting janome>=0.4.2 (from flair)\n",
      "  Downloading Janome-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from flair) (1.0.9)\n",
      "Collecting lxml>=4.8.0 (from flair)\n",
      "  Using cached lxml-5.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from flair) (3.7.4)\n",
      "Requirement already satisfied: more-itertools>=8.13.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from flair) (10.2.0)\n",
      "Collecting mpld3>=0.3 (from flair)\n",
      "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pptree>=3.1 (from flair)\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from flair) (2.8.2)\n",
      "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Collecting regex>=2022.1.18 (from flair)\n",
      "  Using cached regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting scikit-learn>=1.0.2 (from flair)\n",
      "  Using cached scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting segtok>=1.5.11 (from flair)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tabulate>=0.8.10 (from flair)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from flair) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.63.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from flair) (4.66.1)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
      "  Downloading transformer_smaller_training_vocab-0.3.3-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting transformers<5.0.0,>=4.18.0 (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<2.0.0,>=1.0.0 (from flair)\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair)\n",
      "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting semver<4.0.0,>=3.0.0 (from flair)\n",
      "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.43 (from boto3>=1.20.27->flair)\n",
      "  Downloading botocore-1.34.43-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.20.27->flair)\n",
      "  Using cached s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from bpemb>=0.3.2->flair) (1.24.4)\n",
      "Requirement already satisfied: requests in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from bpemb>=0.3.2->flair) (2.31.0)\n",
      "Collecting sentencepiece (from bpemb>=0.3.2->flair)\n",
      "  Downloading sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.13->flair)\n",
      "  Downloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from gdown>=4.4.0->flair) (4.12.3)\n",
      "Requirement already satisfied: filelock in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from gdown>=4.4.0->flair) (3.13.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from gensim>=4.2.0->flair) (1.10.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim>=4.2.0->flair)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (2024.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (23.2)\n",
      "Requirement already satisfied: six in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from langdetect>=1.0.9->flair) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (6.1.1)\n",
      "Requirement already satisfied: jinja2 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from mpld3>=0.3->flair) (3.1.3)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=1.0.2->flair)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=1.0.2->flair)\n",
      "  Downloading threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sympy in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.8,>=1.5.0->flair) (12.3.101)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
      "  Downloading tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
      "  Downloading safetensors-0.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: protobuf in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (4.25.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib>=2.2.3->flair) (3.17.0)\n",
      "Collecting accelerate>=0.21.0 (from transformers[torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair)\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from jinja2->mpld3>=0.3->flair) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from requests->bpemb>=0.3.2->flair) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from requests->bpemb>=0.3.2->flair) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from requests->bpemb>=0.3.2->flair) (2024.2.2)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=4.4.0->flair)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
      "Requirement already satisfied: psutil in /home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages (from accelerate>=0.21.0->transformers[torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.8)\n",
      "Downloading flair-0.13.1-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.34.43-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading gensim-4.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached lxml-5.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
      "Downloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n",
      "Using cached scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Downloading transformer_smaller_training_vocab-0.3.3-py3-none-any.whl (14 kB)\n",
      "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
      "Downloading botocore-1.34.43-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "Downloading safetensors-0.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Downloading tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pptree, sqlitedict\n",
      "  Building wheel for pptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4628 sha256=6ea2a34c42d065b552116a57324d7b2deff67319e11c2283bcafaf7736d71d3c\n",
      "  Stored in directory: /home/ajkdrag/.cache/pip/wheels/e1/8b/30/5b20240d3d13a9dfafb6a6dd49d1b541c86d39812cb3690edf\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16853 sha256=d71a8f21e485716b02ba8a82ffd3b082484bc95c7696f19058a21cf5e99dd6b4\n",
      "  Stored in directory: /home/ajkdrag/.cache/pip/wheels/04/c6/16/46e174009277f9bccdaa7215a243939d2f70180804b249bf3a\n",
      "Successfully built pptree sqlitedict\n",
      "Installing collected packages: sqlitedict, sentencepiece, pptree, janome, wrapt, urllib3, threadpoolctl, tabulate, smart-open, semver, safetensors, regex, PySocks, lxml, joblib, jmespath, ftfy, conllu, segtok, scikit-learn, gensim, deprecated, botocore, wikipedia-api, s3transfer, mpld3, bpemb, tokenizers, pytorch-revgrad, gdown, boto3, accelerate, transformers, transformer-smaller-training-vocab, flair\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.0\n",
      "    Uninstalling urllib3-2.2.0:\n",
      "      Successfully uninstalled urllib3-2.2.0\n",
      "Successfully installed PySocks-1.7.1 accelerate-0.27.2 boto3-1.34.43 botocore-1.34.43 bpemb-0.3.4 conllu-4.5.3 deprecated-1.2.14 flair-0.13.1 ftfy-6.1.3 gdown-5.1.0 gensim-4.3.2 janome-0.5.0 jmespath-1.0.1 joblib-1.3.2 lxml-5.1.0 mpld3-0.5.10 pptree-3.1 pytorch-revgrad-0.2.0 regex-2023.12.25 s3transfer-0.10.0 safetensors-0.4.2 scikit-learn-1.3.2 segtok-1.5.11 semver-3.0.2 sentencepiece-0.1.99 smart-open-6.4.0 sqlitedict-2.1.0 tabulate-0.9.0 threadpoolctl-3.3.0 tokenizers-0.15.2 transformer-smaller-training-vocab-0.3.3 transformers-4.37.2 urllib3-1.26.18 wikipedia-api-0.6.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "65d9105c-77a6-4f87-9f98-3d00c785d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e01ad001-eba2-4e51-89be-5fc500f3fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import TREC_6\n",
    "from flair.models import TARSClassifier\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be634c58-5472-40f1-bf98-388f4639ec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:47:23,715 TARS initialized without a task. You need to call .add_and_switch_to_new_task() before training this model\n"
     ]
    }
   ],
   "source": [
    "tars = TARSClassifier.load(\"tars-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adf120fd-95a6-4573-a756-f84d2dab2928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:52:29,947 No dev split found. Using 0% (i.e. 0 samples) of the train split as dev data\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import FlairDatapointDataset\n",
    "# training dataset consisting of four sentences (2 labeled as \"olahraga\" (sports) and 2 labeled as \"politik\" (politics)\n",
    "train = FlairDatapointDataset(\n",
    "    [\n",
    "        Sentence('BSN Sports LLC')\n",
    "        .add_label('payee_or_misc', 'payee'),\n",
    "        Sentence('Samuel L. Catherin')\n",
    "        .add_label('payee_or_misc', 'payee'),\n",
    "        Sentence('Five Seasons')\n",
    "        .add_label('payee_or_misc', 'payee'),\n",
    "        Sentence('fifty thousand and 00/11')\n",
    "        .add_label('payee_or_misc', 'misc'),\n",
    "        Sentence('Official check')\n",
    "        .add_label('payee_or_misc', 'misc')\n",
    "    ])\n",
    "test = FlairDatapointDataset(\n",
    "    [\n",
    "        Sentence('Central hudson electric').add_label('payee_or_misc', 'payee'),\n",
    "        Sentence('Pay to the order of').add_label('payee_or_misc', 'misc')\n",
    "    ])\n",
    "# make a corpus with train and test split\n",
    "corpus = Corpus(train=train, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7cdfb01-0038-4d2a-8bf1-15a0a9724058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:54:53,433 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "5it [00:00, 12710.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:54:53,439 Dictionary created for label 'payee_or_misc' with 2 values: payee (seen 3 times), misc (seen 2 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<flair.data.Dictionary at 0x7f01fec99be0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.make_label_dictionary(label_type=\"payee_or_misc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf76001c-4371-424b-93d4-281be8e69dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:55:25,508 TARS initialized without a task. You need to call .add_and_switch_to_new_task() before training this model\n",
      "2024-02-17 00:55:25,567 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "5it [00:00, 12045.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:55:25,573 Dictionary created for label 'payee_or_misc' with 2 values: payee (seen 3 times), misc (seen 2 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "# 1. load base TARS\n",
    "tars = TARSClassifier.load('tars-base')\n",
    "# 2. make the model aware of the desired set of labels from the new corpus\n",
    "tars.add_and_switch_to_new_task(\"PAYEE_OR_MISC\", \n",
    "                                label_dictionary=corpus.make_label_dictionary(\"payee_or_misc\"),\n",
    "                                label_type=\"payee_or_misc\")\n",
    "# 3. initialize the text classifier trainer with your corpus\n",
    "trainer = ModelTrainer(tars, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c53f33b0-9592-47bb-8823-7715405bc505",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:55:51,709 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,711 Model: \"TARSClassifier(\n",
      "  (tars_model): TextClassifier(\n",
      "    (embeddings): TransformerDocumentEmbeddings(\n",
      "      (model): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0-11): 12 x BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (locked_dropout): LockedDropout(p=0.0)\n",
      "    (word_dropout): WordDropout(p=0.0)\n",
      "    (loss_function): CrossEntropyLoss()\n",
      "  )\n",
      ")\"\n",
      "2024-02-17 00:55:51,712 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,712 Corpus: 5 train + 0 dev + 2 test sentences\n",
      "2024-02-17 00:55:51,713 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,713 Train:  5 sentences\n",
      "2024-02-17 00:55:51,714         (train_with_dev=False, train_with_test=False)\n",
      "2024-02-17 00:55:51,714 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,715 Training Params:\n",
      "2024-02-17 00:55:51,715  - learning_rate: \"0.02\" \n",
      "2024-02-17 00:55:51,715  - mini_batch_size: \"1\"\n",
      "2024-02-17 00:55:51,716  - max_epochs: \"10\"\n",
      "2024-02-17 00:55:51,716  - shuffle: \"True\"\n",
      "2024-02-17 00:55:51,717 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,717 Plugins:\n",
      "2024-02-17 00:55:51,718  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
      "2024-02-17 00:55:51,718 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,719 Final evaluation on model from best epoch (best-model.pt)\n",
      "2024-02-17 00:55:51,719  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-02-17 00:55:51,722 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,722 Computation:\n",
      "2024-02-17 00:55:51,723  - compute on device: cuda:0\n",
      "2024-02-17 00:55:51,724  - embedding storage: cpu\n",
      "2024-02-17 00:55:51,724 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,725 Model training base path: \"resources/taggers/payee\"\n",
      "2024-02-17 00:55:51,725 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,726 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,803 epoch 1 - iter 1/5 - loss 2.10815310 - time (sec): 0.05 - samples/sec: 40.92 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:51,834 epoch 1 - iter 2/5 - loss 1.52426022 - time (sec): 0.08 - samples/sec: 50.02 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:51,871 epoch 1 - iter 3/5 - loss 1.86336601 - time (sec): 0.12 - samples/sec: 51.29 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:51,910 epoch 1 - iter 4/5 - loss 1.93622264 - time (sec): 0.16 - samples/sec: 51.14 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:51,939 epoch 1 - iter 5/5 - loss 1.97919791 - time (sec): 0.19 - samples/sec: 53.96 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:51,940 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:51,941 EPOCH 1 done: loss 1.9792 - lr: 0.020000\n",
      "2024-02-17 00:55:51,942  - 0 epochs without improvement\n",
      "2024-02-17 00:55:51,943 saving best model\n",
      "2024-02-17 00:55:52,373 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,412 epoch 2 - iter 1/5 - loss 0.68676007 - time (sec): 0.03 - samples/sec: 77.06 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,442 epoch 2 - iter 2/5 - loss 0.84860581 - time (sec): 0.06 - samples/sec: 71.94 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,471 epoch 2 - iter 3/5 - loss 0.84427923 - time (sec): 0.08 - samples/sec: 70.72 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,500 epoch 2 - iter 4/5 - loss 0.80891456 - time (sec): 0.11 - samples/sec: 70.44 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,533 epoch 2 - iter 5/5 - loss 0.76621665 - time (sec): 0.15 - samples/sec: 67.86 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,534 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,535 EPOCH 2 done: loss 0.7662 - lr: 0.020000\n",
      "2024-02-17 00:55:52,536  - 1 epochs without improvement\n",
      "2024-02-17 00:55:52,538 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,581 epoch 3 - iter 1/5 - loss 0.13155100 - time (sec): 0.03 - samples/sec: 64.92 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,610 epoch 3 - iter 2/5 - loss 0.51108031 - time (sec): 0.06 - samples/sec: 66.26 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,645 epoch 3 - iter 3/5 - loss 0.91648836 - time (sec): 0.10 - samples/sec: 62.89 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,675 epoch 3 - iter 4/5 - loss 0.73741844 - time (sec): 0.12 - samples/sec: 64.13 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,704 epoch 3 - iter 5/5 - loss 0.61619696 - time (sec): 0.15 - samples/sec: 64.82 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,705 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,706 EPOCH 3 done: loss 0.6162 - lr: 0.020000\n",
      "2024-02-17 00:55:52,707  - 2 epochs without improvement\n",
      "2024-02-17 00:55:52,708 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,746 epoch 4 - iter 1/5 - loss 0.04814388 - time (sec): 0.03 - samples/sec: 76.11 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,781 epoch 4 - iter 2/5 - loss 0.03209685 - time (sec): 0.06 - samples/sec: 65.03 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,817 epoch 4 - iter 3/5 - loss 0.02594506 - time (sec): 0.10 - samples/sec: 61.85 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,846 epoch 4 - iter 4/5 - loss 0.20615928 - time (sec): 0.13 - samples/sec: 63.26 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,876 epoch 4 - iter 5/5 - loss 0.16739294 - time (sec): 0.16 - samples/sec: 63.95 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:52,877 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:52,878 EPOCH 4 done: loss 0.1674 - lr: 0.020000\n",
      "2024-02-17 00:55:52,879  - 3 epochs without improvement\n",
      "2024-02-17 00:55:52,880 saving best model\n",
      "2024-02-17 00:55:53,435 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:53,477 epoch 5 - iter 1/5 - loss 0.00357518 - time (sec): 0.03 - samples/sec: 76.27 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,505 epoch 5 - iter 2/5 - loss 0.05364135 - time (sec): 0.05 - samples/sec: 73.05 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,535 epoch 5 - iter 3/5 - loss 0.04225065 - time (sec): 0.08 - samples/sec: 70.62 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,575 epoch 5 - iter 4/5 - loss 0.03348753 - time (sec): 0.13 - samples/sec: 63.95 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,604 epoch 5 - iter 5/5 - loss 0.05917075 - time (sec): 0.15 - samples/sec: 65.02 - lr: 0.020000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,605 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:53,605 EPOCH 5 done: loss 0.0592 - lr: 0.020000\n",
      "2024-02-17 00:55:53,607  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.01]\n",
      "2024-02-17 00:55:53,608 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:53,647 epoch 6 - iter 1/5 - loss 0.00647313 - time (sec): 0.03 - samples/sec: 76.94 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,676 epoch 6 - iter 2/5 - loss 0.01799789 - time (sec): 0.05 - samples/sec: 72.81 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,710 epoch 6 - iter 3/5 - loss 0.01216121 - time (sec): 0.09 - samples/sec: 67.53 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,742 epoch 6 - iter 4/5 - loss 0.00992067 - time (sec): 0.12 - samples/sec: 65.88 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,780 epoch 6 - iter 5/5 - loss 0.00907170 - time (sec): 0.16 - samples/sec: 62.79 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:53,781 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:53,782 EPOCH 6 done: loss 0.0091 - lr: 0.010000\n",
      "2024-02-17 00:55:53,783  - 1 epochs without improvement\n",
      "2024-02-17 00:55:53,784 saving best model\n",
      "2024-02-17 00:55:54,185 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,241 epoch 7 - iter 1/5 - loss 0.00313355 - time (sec): 0.03 - samples/sec: 72.51 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,270 epoch 7 - iter 2/5 - loss 0.00177167 - time (sec): 0.06 - samples/sec: 70.10 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,301 epoch 7 - iter 3/5 - loss 0.00205998 - time (sec): 0.09 - samples/sec: 67.87 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,338 epoch 7 - iter 4/5 - loss 0.00171531 - time (sec): 0.13 - samples/sec: 63.93 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,370 epoch 7 - iter 5/5 - loss 0.00175350 - time (sec): 0.16 - samples/sec: 63.75 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,371 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,371 EPOCH 7 done: loss 0.0018 - lr: 0.010000\n",
      "2024-02-17 00:55:54,373  - 2 epochs without improvement\n",
      "2024-02-17 00:55:54,374 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,413 epoch 8 - iter 1/5 - loss 0.00157913 - time (sec): 0.03 - samples/sec: 75.08 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,443 epoch 8 - iter 2/5 - loss 0.00095258 - time (sec): 0.06 - samples/sec: 71.17 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,472 epoch 8 - iter 3/5 - loss 0.00663488 - time (sec): 0.09 - samples/sec: 69.91 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,510 epoch 8 - iter 4/5 - loss 0.00516349 - time (sec): 0.12 - samples/sec: 64.92 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,538 epoch 8 - iter 5/5 - loss 0.00415431 - time (sec): 0.15 - samples/sec: 65.72 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,539 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,540 EPOCH 8 done: loss 0.0042 - lr: 0.010000\n",
      "2024-02-17 00:55:54,541  - 3 epochs without improvement\n",
      "2024-02-17 00:55:54,543 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,591 epoch 9 - iter 1/5 - loss 0.00200971 - time (sec): 0.03 - samples/sec: 74.88 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,619 epoch 9 - iter 2/5 - loss 0.00166987 - time (sec): 0.05 - samples/sec: 73.35 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,648 epoch 9 - iter 3/5 - loss 0.00121260 - time (sec): 0.08 - samples/sec: 71.76 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,678 epoch 9 - iter 4/5 - loss 0.00142340 - time (sec): 0.11 - samples/sec: 70.38 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,713 epoch 9 - iter 5/5 - loss 0.00147699 - time (sec): 0.15 - samples/sec: 67.13 - lr: 0.010000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,714 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,715 EPOCH 9 done: loss 0.0015 - lr: 0.010000\n",
      "2024-02-17 00:55:54,716  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.005]\n",
      "2024-02-17 00:55:54,717 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,756 epoch 10 - iter 1/5 - loss 0.00121854 - time (sec): 0.03 - samples/sec: 73.37 - lr: 0.005000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,803 epoch 10 - iter 2/5 - loss 0.00298219 - time (sec): 0.07 - samples/sec: 54.20 - lr: 0.005000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,830 epoch 10 - iter 3/5 - loss 0.00254319 - time (sec): 0.10 - samples/sec: 59.22 - lr: 0.005000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,866 epoch 10 - iter 4/5 - loss 0.00224540 - time (sec): 0.14 - samples/sec: 58.51 - lr: 0.005000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,902 epoch 10 - iter 5/5 - loss 0.00187507 - time (sec): 0.17 - samples/sec: 57.90 - lr: 0.005000 - momentum: 0.000000\n",
      "2024-02-17 00:55:54,903 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:54,903 EPOCH 10 done: loss 0.0019 - lr: 0.005000\n",
      "2024-02-17 00:55:54,904  - 1 epochs without improvement\n",
      "2024-02-17 00:55:55,542 ----------------------------------------------------------------------------------------------------\n",
      "2024-02-17 00:55:55,544 Loading model from best epoch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 89.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 00:55:57,553 \n",
      "Results:\n",
      "- F-score (micro) 0.5\n",
      "- F-score (macro) 0.3333\n",
      "- Accuracy 0.5\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       payee     0.5000    1.0000    0.6667         1\n",
      "        misc     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.5000         2\n",
      "   macro avg     0.2500    0.5000    0.3333         2\n",
      "weighted avg     0.2500    0.5000    0.3333         2\n",
      "\n",
      "2024-02-17 00:55:57,554 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.5}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. train model\n",
    "trainer.train(base_path='resources/taggers/payee', # path to store the model artifacts\n",
    "              learning_rate=0.02, \n",
    "              mini_batch_size=1, \n",
    "              max_epochs=10, \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cfce056-c57d-4986-959c-9c6b6b8fadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load few-shot TARS model\n",
    "tars = TARSClassifier.load('resources/taggers/payee/final-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45cd4fe1-f558-42e6-b704-29285ec0e531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[3]: \"Weber County Treasurer\"\n"
     ]
    }
   ],
   "source": [
    "# 6. Prepare a test sentence\n",
    "sentence = Sentence(\"Weber County Treasurer\")\n",
    "# 7. Predict for olahraga and politik\n",
    "tars.predict(sentence, return_probabilities_for_all_classes=True)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e3834-39de-485b-a36a-d3011a0e12e0",
   "metadata": {},
   "source": [
    "## trying wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "042181e0-d9d1-4811-a50c-1298db2d5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install -q pytorch-widedeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "013b10e1-27f2-4698-b690-6a21d7352f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor, TextPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep, TabResnet, BasicRNN\n",
    "from pytorch_widedeep.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ae9ad3e5-28db-477e-8155-66300e044045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = pd.read_csv(\"temp/merged_train.csv\"), pd.read_csv(\"temp/merged_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "02a8d91f-e9ba-44fc-8ec3-28921abdd8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_cols = [\n",
    "    ('payee_txt', 12)\n",
    "]\n",
    "cont_cols = ['anchor_x1', 'anchor_y1', 'anchor_x2', 'anchor_y2', 'payee_x1',\n",
    "       'payee_y1', 'payee_x2', 'payee_y2']\n",
    "\n",
    "df_train.drop([\"idx\"], axis=1, inplace=True)\n",
    "df_test.drop([\"idx\"], axis=1, inplace=True)\n",
    "\n",
    "target = df_train[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0e52776e-76d0-4855-8560-54d0ae618117",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessor = TextPreprocessor(text_col=\"payee_txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff4e60e-0279-4a49-b6b0-6d2847ff12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c0f955c0-42cb-4582-8e1a-c4e6258ecad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary contains 160 tokens\n"
     ]
    }
   ],
   "source": [
    "X_text = text_preprocessor.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8992aedb-7a9d-48f1-b910-60397febbe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajkdrag/workspace/ocrtoolkit/venv/lib/python3.8/site-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:360: UserWarning: Continuous columns will not be normalised\n",
      "  warnings.warn(\"Continuous columns will not be normalised\")\n"
     ]
    }
   ],
   "source": [
    "tab_preprocessor = TabPreprocessor(continuous_cols=cont_cols,\n",
    "                                   verbose=1)\n",
    "X_tab = tab_preprocessor.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bd5db132-8e96-4868-8138-75c3e99e9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepDense: 2 Dense layers\n",
    "tab_mlp = TabMlp(\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    continuous_cols=cont_cols,\n",
    "    mlp_hidden_dims=[128, 64],\n",
    "    mlp_dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a8676a75-45d1-43a6-98f0-d8e6b1cca984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepText: a stack of 2 LSTMs\n",
    "basic_rnn = BasicRNN(\n",
    "    vocab_size=len(text_preprocessor.vocab.itos),\n",
    "    n_layers=2,\n",
    "    embed_dim=8,\n",
    "    hidden_dim=64,\n",
    "    rnn_dropout=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c5436dfe-4e06-421d-b2fe-c5d9140c0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideDeep(\n",
    "    deeptabular=tab_mlp,\n",
    "    deeptext=basic_rnn,\n",
    "    head_hidden_dims=[256, 128],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4bd9196c-59b3-49b2-91a1-3af769035ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|█████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 70.21it/s, loss=0.409, metrics={'acc': 0.8027}]\n",
      "epoch 2: 100%|█████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 52.94it/s, loss=0.122, metrics={'acc': 0.9628}]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.94it/s, loss=0.0636, metrics={'acc': 0.9753}]\n",
      "epoch 3: 100%|████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 74.28it/s, loss=0.0859, metrics={'acc': 0.9717}]\n",
      "epoch 4: 100%|████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 77.02it/s, loss=0.0715, metrics={'acc': 0.9752}]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 39.70it/s, loss=0.0393, metrics={'acc': 0.9823}]\n",
      "epoch 5: 100%|████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 62.12it/s, loss=0.0486, metrics={'acc': 0.9814}]\n",
      "epoch 6: 100%|████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 76.10it/s, loss=0.0389, metrics={'acc': 0.9832}]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 38.66it/s, loss=0.0413, metrics={'acc': 0.9894}]\n",
      "epoch 7: 100%|████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 75.78it/s, loss=0.0327, metrics={'acc': 0.9858}]\n",
      "epoch 8: 100%|████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 70.11it/s, loss=0.0356, metrics={'acc': 0.9885}]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 38.78it/s, loss=0.0508, metrics={'acc': 0.9823}]\n",
      "epoch 9: 100%|████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 74.04it/s, loss=0.0378, metrics={'acc': 0.9885}]\n",
      "epoch 10: 100%|████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 67.30it/s, loss=0.0302, metrics={'acc': 0.992}]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.46it/s, loss=0.0585, metrics={'acc': 0.9823}]\n",
      "epoch 11: 100%|███████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 74.18it/s, loss=0.0295, metrics={'acc': 0.9894}]\n",
      "epoch 12: 100%|█████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 55.23it/s, loss=0.023, metrics={'acc': 0.992}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 29.65it/s, loss=0.061, metrics={'acc': 0.9859}]\n",
      "epoch 13: 100%|███████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 67.71it/s, loss=0.0435, metrics={'acc': 0.9858}]\n",
      "epoch 14: 100%|███████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 77.31it/s, loss=0.0251, metrics={'acc': 0.9903}]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 35.77it/s, loss=0.0504, metrics={'acc': 0.9894}]\n",
      "epoch 15: 100%|████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 70.16it/s, loss=0.0234, metrics={'acc': 0.992}]\n",
      "epoch 16: 100%|███████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 75.47it/s, loss=0.0198, metrics={'acc': 0.9929}]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 38.58it/s, loss=0.0648, metrics={'acc': 0.9894}]\n",
      "epoch 17: 100%|███████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 70.11it/s, loss=0.0139, metrics={'acc': 0.9938}]\n",
      "epoch 18: 100%|███████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 66.57it/s, loss=0.0179, metrics={'acc': 0.9947}]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.49it/s, loss=0.0768, metrics={'acc': 0.9859}]\n",
      "epoch 19: 100%|████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 71.42it/s, loss=0.027, metrics={'acc': 0.9876}]\n",
      "epoch 20: 100%|███████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 73.41it/s, loss=0.0239, metrics={'acc': 0.9938}]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.63it/s, loss=0.0579, metrics={'acc': 0.9788}]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, objective=\"binary\", metrics=[(Accuracy)])\n",
    "trainer.fit(X_tab=X_tab, \n",
    "            X_text=X_text,\n",
    "            target=target, n_epochs=20, \n",
    "            batch_size=32, val_split=0.2, validation_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffac0a7-f6cc-499e-9303-a1aa2a9192cf",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fc167d67-ad03-4a91-827e-fd70edcaffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 42.83it/s]\n"
     ]
    }
   ],
   "source": [
    "X_tab_te = tab_preprocessor.transform(df_test)\n",
    "X_text_te = text_preprocessor.transform(df_test)\n",
    "preds = trainer.predict(X_tab=X_tab_te, X_text=X_text_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "314775b4-4927-4149-857e-27f1bca3240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "41a1fc63-5232-4571-aee3-d2c5c366ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"temp/tab_preproc.pkl\", \"wb\") as dp:\n",
    "#     pickle.dump(tab_preprocessor, dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8659dca0-e0b5-4d14-872e-b7a0e1598781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"temp/text_preproc.pkl\", \"wb\") as dp:\n",
    "#     pickle.dump(text_preprocessor, dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a41c1d20-9122-415a-b638-8382d6657797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"temp/model_saved.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3ac23-edd0-4801-9f77-3bdbda0f0559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f3fc8-d17f-4356-8007-77f0f589f94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "df13cba8-de05-4baf-8a43-ece79fd1397b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766081871345029"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds == df_test[\"target\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8c1517ac-7236-4e06-89c1-419582abe915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766081871345029"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_test[\"target\"].values, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda6386b-cc90-49a3-8834-5e8ae2c08ffd",
   "metadata": {},
   "source": [
    "## xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "369e5289-bffc-4331-bd73-23fdc75d4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabmlp = TabMlp(\n",
    "    mlp_hidden_dims=[200, 100],\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    continuous_cols=cont_cols,\n",
    "    mlp_batchnorm_last=True,\n",
    "    cont_norm_layer=\"batchnorm\"\n",
    ")\n",
    "model = WideDeep(deeptabular=tabmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fabd9493-903f-471d-b928-a2225ede177d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 16.38it/s, loss=0.376, metrics={'acc': 0.834}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.12it/s, loss=0.453, metrics={'acc': 0.8316}]\n",
      "epoch 2: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 13.22it/s, loss=0.355, metrics={'acc': 0.834}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s, loss=0.436, metrics={'acc': 0.8316}]\n",
      "epoch 3: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 13.89it/s, loss=0.337, metrics={'acc': 0.834}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.13it/s, loss=0.413, metrics={'acc': 0.8316}]\n",
      "epoch 4: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 14.55it/s, loss=0.324, metrics={'acc': 0.8511}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.93it/s, loss=0.389, metrics={'acc': 0.8474}]\n",
      "epoch 5: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 13.02it/s, loss=0.312, metrics={'acc': 0.863}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.06it/s, loss=0.368, metrics={'acc': 0.8526}]\n",
      "epoch 6: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 13.72it/s, loss=0.299, metrics={'acc': 0.8682}]\n",
      "valid: 100%|██████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.43it/s, loss=0.35, metrics={'acc': 0.8474}]\n",
      "epoch 7: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 14.51it/s, loss=0.289, metrics={'acc': 0.8735}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, loss=0.334, metrics={'acc': 0.8526}]\n",
      "epoch 8: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 14.62it/s, loss=0.272, metrics={'acc': 0.888}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.34it/s, loss=0.319, metrics={'acc': 0.8579}]\n",
      "epoch 9: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 13.74it/s, loss=0.265, metrics={'acc': 0.8933}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.24it/s, loss=0.305, metrics={'acc': 0.8579}]\n",
      "epoch 10: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 13.87it/s, loss=0.257, metrics={'acc': 0.8959}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s, loss=0.291, metrics={'acc': 0.8737}]\n",
      "epoch 11: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 14.87it/s, loss=0.249, metrics={'acc': 0.8986}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.75it/s, loss=0.279, metrics={'acc': 0.8737}]\n",
      "epoch 12: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 14.05it/s, loss=0.234, metrics={'acc': 0.9012}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.10it/s, loss=0.268, metrics={'acc': 0.8895}]\n",
      "epoch 13: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 13.81it/s, loss=0.228, metrics={'acc': 0.9025}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.25it/s, loss=0.259, metrics={'acc': 0.8895}]\n",
      "epoch 14: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 12.97it/s, loss=0.221, metrics={'acc': 0.9025}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.67it/s, loss=0.252, metrics={'acc': 0.8947}]\n",
      "epoch 15: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 13.24it/s, loss=0.208, metrics={'acc': 0.9144}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.79it/s, loss=0.246, metrics={'acc': 0.9053}]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, objective=\"binary\", metrics=[(Accuracy)])\n",
    "trainer.fit(X_tab=X_tab, target=target, n_epochs=15, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1a8761e1-78cd-4aed-8d8d-fa71b0527916",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabresnet = TabResnet(\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    cat_embed_input=tab_preprocessor.cat_embed_input, \n",
    "    continuous_cols=cont_cols,\n",
    "    mlp_batchnorm_last=True,\n",
    "    cont_norm_layer=\"batchnorm\",\n",
    "    blocks_dims=[200, 100, 100],\n",
    "    mlp_hidden_dims=[100, 50],\n",
    ")\n",
    "model2 = WideDeep(deeptabular=tabresnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6ea26aa5-b3e5-4a76-b1d4-57ddc12cb814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 11.93it/s, loss=0.648, metrics={'acc': 0.776}]\n",
      "valid: 100%|██████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.08it/s, loss=0.65, metrics={'acc': 0.8316}]\n",
      "epoch 2: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 11.49it/s, loss=0.545, metrics={'acc': 0.834}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s, loss=0.605, metrics={'acc': 0.8316}]\n",
      "epoch 3: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 11.75it/s, loss=0.457, metrics={'acc': 0.834}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s, loss=0.539, metrics={'acc': 0.8316}]\n",
      "epoch 4: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 10.45it/s, loss=0.41, metrics={'acc': 0.834}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.13it/s, loss=0.486, metrics={'acc': 0.8316}]\n",
      "epoch 5: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 10.58it/s, loss=0.396, metrics={'acc': 0.834}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.48it/s, loss=0.475, metrics={'acc': 0.8316}]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model2, objective=\"binary\", metrics=[(Accuracy)])\n",
    "trainer.fit(X_tab=X_tab, target=target, n_epochs=5, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cd867f63-613e-4854-9190-178601ddd49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_preprocessor2 = TabPreprocessor(\n",
    "    embed_cols=['payee_txt'],\n",
    "    continuous_cols=cont_cols,\n",
    "    cols_to_scale=\"all\",\n",
    "    with_attention=True)\n",
    "\n",
    "X_tab2 = tab_preprocessor2.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5b904a02-c819-43c7-8e3e-6e8c02e08295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('payee_txt', 749)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_preprocessor2.cat_embed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "25ad649e-c317-47dd-b576-0b0fbb6fadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.models import TabTransformer\n",
    "\n",
    "tabtransformer = TabTransformer(\n",
    "    column_idx=tab_preprocessor2.column_idx,\n",
    "    cat_embed_input=tab_preprocessor2.cat_embed_input, \n",
    "    continuous_cols=cont_cols,\n",
    "    shared_embed=True,\n",
    "    n_blocks=3,\n",
    ")\n",
    "model3 = WideDeep(deeptabular=tabtransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "302e7147-4c08-482e-b643-6b4da34fbbde",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  6.49it/s, loss=0.648, metrics={'acc': 0.6311}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.01it/s, loss=0.574, metrics={'acc': 0.7684}]\n",
      "epoch 2: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 11.08it/s, loss=0.546, metrics={'acc': 0.8063}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s, loss=0.504, metrics={'acc': 0.8263}]\n",
      "epoch 3: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 10.99it/s, loss=0.486, metrics={'acc': 0.83}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s, loss=0.462, metrics={'acc': 0.8316}]\n",
      "epoch 4: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  9.85it/s, loss=0.449, metrics={'acc': 0.834}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s, loss=0.443, metrics={'acc': 0.8316}]\n",
      "epoch 5: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 10.28it/s, loss=0.427, metrics={'acc': 0.834}]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.96it/s, loss=0.439, metrics={'acc': 0.8316}]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model3, objective=\"binary\", metrics=[(Accuracy)])\n",
    "trainer.fit(X_tab=X_tab2, target=target, n_epochs=5, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4ce45c49-c0c6-406b-9ad9-baeaed7f7487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor_x1</th>\n",
       "      <th>anchor_y1</th>\n",
       "      <th>anchor_x2</th>\n",
       "      <th>anchor_y2</th>\n",
       "      <th>payee_x1</th>\n",
       "      <th>payee_y1</th>\n",
       "      <th>payee_x2</th>\n",
       "      <th>payee_y2</th>\n",
       "      <th>payee_txt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035898</td>\n",
       "      <td>0.209373</td>\n",
       "      <td>0.076653</td>\n",
       "      <td>0.271838</td>\n",
       "      <td>0.307863</td>\n",
       "      <td>0.181312</td>\n",
       "      <td>0.679726</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>Shiva Prasad Kumar veduger канди .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037499</td>\n",
       "      <td>0.221835</td>\n",
       "      <td>0.076550</td>\n",
       "      <td>0.271920</td>\n",
       "      <td>0.307751</td>\n",
       "      <td>0.181188</td>\n",
       "      <td>0.679659</td>\n",
       "      <td>0.281151</td>\n",
       "      <td>Shiva Prasad Kumar veduger канди .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071929</td>\n",
       "      <td>0.296898</td>\n",
       "      <td>0.095270</td>\n",
       "      <td>0.340562</td>\n",
       "      <td>0.114106</td>\n",
       "      <td>0.284404</td>\n",
       "      <td>0.173461</td>\n",
       "      <td>0.337421</td>\n",
       "      <td>SELF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.303185</td>\n",
       "      <td>0.101585</td>\n",
       "      <td>0.343738</td>\n",
       "      <td>0.114024</td>\n",
       "      <td>0.284368</td>\n",
       "      <td>0.173377</td>\n",
       "      <td>0.337462</td>\n",
       "      <td>SELF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.215634</td>\n",
       "      <td>0.062554</td>\n",
       "      <td>0.268689</td>\n",
       "      <td>0.084344</td>\n",
       "      <td>0.209328</td>\n",
       "      <td>0.273478</td>\n",
       "      <td>0.262429</td>\n",
       "      <td>ANKIT SHARMA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.020305</td>\n",
       "      <td>0.150076</td>\n",
       "      <td>0.076542</td>\n",
       "      <td>0.199937</td>\n",
       "      <td>0.029726</td>\n",
       "      <td>0.162497</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>0.200041</td>\n",
       "      <td>PAY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.020394</td>\n",
       "      <td>0.149926</td>\n",
       "      <td>0.076631</td>\n",
       "      <td>0.199961</td>\n",
       "      <td>0.036004</td>\n",
       "      <td>0.303098</td>\n",
       "      <td>0.496804</td>\n",
       "      <td>0.418716</td>\n",
       "      <td>TRUPEES One Саки IV Thirty five</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.024913</td>\n",
       "      <td>0.156321</td>\n",
       "      <td>0.067278</td>\n",
       "      <td>0.212457</td>\n",
       "      <td>0.078057</td>\n",
       "      <td>0.574923</td>\n",
       "      <td>0.371906</td>\n",
       "      <td>0.624956</td>\n",
       "      <td>ORIENTAL BANK OF COMMERCE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.024970</td>\n",
       "      <td>0.156172</td>\n",
       "      <td>0.067230</td>\n",
       "      <td>0.212470</td>\n",
       "      <td>0.029594</td>\n",
       "      <td>0.162537</td>\n",
       "      <td>0.062435</td>\n",
       "      <td>0.199968</td>\n",
       "      <td>PAY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.024927</td>\n",
       "      <td>0.156257</td>\n",
       "      <td>0.067268</td>\n",
       "      <td>0.212464</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.303035</td>\n",
       "      <td>0.496936</td>\n",
       "      <td>0.418823</td>\n",
       "      <td>TRUPEES One Саки IV Thirty five</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     anchor_x1  anchor_y1  anchor_x2  anchor_y2  payee_x1  payee_y1  payee_x2  \\\n",
       "0     0.035898   0.209373   0.076653   0.271838  0.307863  0.181312  0.679726   \n",
       "1     0.037499   0.221835   0.076550   0.271920  0.307751  0.181188  0.679659   \n",
       "2     0.071929   0.296898   0.095270   0.340562  0.114106  0.284404  0.173461   \n",
       "3     0.070338   0.303185   0.101585   0.343738  0.114024  0.284368  0.173377   \n",
       "4     0.023404   0.215634   0.062554   0.268689  0.084344  0.209328  0.273478   \n",
       "..         ...        ...        ...        ...       ...       ...       ...   \n",
       "337   0.020305   0.150076   0.076542   0.199937  0.029726  0.162497  0.062492   \n",
       "338   0.020394   0.149926   0.076631   0.199961  0.036004  0.303098  0.496804   \n",
       "339   0.024913   0.156321   0.067278   0.212457  0.078057  0.574923  0.371906   \n",
       "340   0.024970   0.156172   0.067230   0.212470  0.029594  0.162537  0.062435   \n",
       "341   0.024927   0.156257   0.067268   0.212464  0.035951  0.303035  0.496936   \n",
       "\n",
       "     payee_y2                           payee_txt  target  \n",
       "0    0.281260  Shiva Prasad Kumar veduger канди .       1  \n",
       "1    0.281151  Shiva Prasad Kumar veduger канди .       1  \n",
       "2    0.337421                                SELF       1  \n",
       "3    0.337462                                SELF       1  \n",
       "4    0.262429                        ANKIT SHARMA       1  \n",
       "..        ...                                 ...     ...  \n",
       "337  0.200041                                 PAY       0  \n",
       "338  0.418716     TRUPEES One Саки IV Thirty five       0  \n",
       "339  0.624956           ORIENTAL BANK OF COMMERCE       0  \n",
       "340  0.199968                                 PAY       0  \n",
       "341  0.418823     TRUPEES One Саки IV Thirty five       0  \n",
       "\n",
       "[342 rows x 10 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9501b972-576c-48ea-a735-b0c9b8a6fa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.65it/s]\n"
     ]
    }
   ],
   "source": [
    "X_tab_te = tab_preprocessor.transform(df_test)\n",
    "preds = trainer.predict(X_tab=X_tab_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a93bbd4-aba1-4ca7-a7c9-2025d952b8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9243697478991597"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df_test[\"target\"] == preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0ce70be-34ac-49ce-afa1-63a1829d74e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61ade12e-6b25-4ad3-8fec-50a8accce34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c499696-4cfc-43aa-b5d7-546c3363d324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
